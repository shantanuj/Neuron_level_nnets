{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Hebbian Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#linearly separable data\n",
    "x = [[1.0,2.5],[2.0,-1.0], [1.5,3.0], [0.0,-1.5], [-3.5,1.0],[2.5,0.0],[0.5,1.5],[0.0,-2.0]]\n",
    "y = [1,0,1,0,1,0,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x, bi =False): # x is a vector (1 rank input) \n",
    "    ind_less_than_equal_0 = np.where(x<=0)\n",
    "    ind_more_than_0 = np.where(x>0) #using this instead of sets incase of multi rank inputs\n",
    "    z = x \n",
    "    z[ind_more_than_0] = 1\n",
    "    if(bi):\n",
    "        z[ind_less_than_equal_0] = -1\n",
    "    else:\n",
    "        z[ind_less_than_equal_0] = 0\n",
    "    return z\n",
    "\n",
    "\n",
    "class neuron:\n",
    "    def __init__(self, x_shape, learning_rate = 0.01): #x_shape is number of inputs #x and y are 2 rank: batch_size*dims\n",
    "        self.xshape = x_shape \n",
    "        self.weights = self.init_weights(x_shape)\n",
    "        #self.bias = np.random.randn(1)\n",
    "        self.activation = step #(bi=True)\n",
    "        self.learning_rate = learning_rate\n",
    "    def init_weights(self, n0):\n",
    "        return np.random.randn(1,n0) #n1 is number of input neurons\n",
    "    def output(self, x): #equivalent to forward pass/activation\n",
    "        pred = self.activation(np.dot(x,np.transpose(self.weights)),False)# + self.bias)\n",
    "        return pred\n",
    "    def param_updates(self, preds, x):\n",
    "        #using formula that delta(weight_i) = learning_rate*(X_i*Y_i +|Y_i-X_i|)\n",
    "        #assume preds to be shape batch_size*1\n",
    "        #BELOW formula assumes weights are only updated after entire batch\n",
    "        self.weights = self.weights + self.learning_rate*np.average(preds*x) #on average activations were so and so\n",
    "        #self.bias = self.bias + self.lear\n",
    "            \n",
    "    def training(self, x,y): #taking y although it is irrelevant for a pure hebbian learner\n",
    "        x = np.array(x)\n",
    "        preds = self.output(x)\n",
    "        preds = preds.reshape(preds.shape[0],1)\n",
    "        self.param_updates(preds, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "hebbian_neuron = neuron(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "hebbian_neuron.training(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.28007653, -0.59577225]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hebbian_neuron.weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hebbian_neuron.output([-5,-1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.625 ,  0.0625])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(preds*x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. , -2.5],\n",
       "       [-2. ,  1. ],\n",
       "       [ 1.5,  3. ],\n",
       "       [ 0. , -1.5],\n",
       "       [ 3.5, -1. ],\n",
       "       [ 2.5,  0. ],\n",
       "       [ 0.5,  1.5],\n",
       "       [ 0. , -0. ]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
